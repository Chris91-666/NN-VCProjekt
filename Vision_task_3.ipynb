{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Recurrent Residual Convolutional Neural Network (Task3)\n",
    "\n",
    "### Simon Laurent Lebailly, 2549365, s9sileba@teams.uni-saarland.de\n",
    "### Christian Mathieu Schmidt, 2537621, s9cmscmi@teams.uni-saarland.de"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1) Preliminaries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Import libaries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cityscapesscripts as cs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Use CUDA if possible"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Check if CUDA is available, if not use the CPU.\n",
    "train_on_GPU = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if train_on_GPU else 'cpu')\n",
    "\n",
    "if train_on_GPU:\n",
    "    print('CUDA available!')\n",
    "else:\n",
    "    print('CUDA not available!')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Define Hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train = True\n",
    "validate = True\n",
    "evaluate = True\n",
    "\n",
    "train_bs = 1\n",
    "validation_bs = 1\n",
    "test_bs = 1\n",
    "\n",
    "epochs = 2\n",
    "\n",
    "learning_rate = 0.0002"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2) Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Import dataset Cityscapes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils import data\n",
    "\n",
    "\n",
    "#Define normalization for dataset\n",
    "normalize = transforms.Normalize(\n",
    "    mean = [0.485, 0.456, 0.406],\n",
    "    std = [0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "#Define transformation for train, validation and test dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256,512)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "class TransformToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        sample_out = (sample*32).long()\n",
    "        return sample_out\n",
    "\n",
    "target_transform = transforms.Compose([\n",
    "    transforms.Resize((256,512)),\n",
    "    transforms.ToTensor(),\n",
    "    TransformToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "#Path of dataset\n",
    "root_path = 'C:/Users/chris/Documents/Cityscapes_dataset/Cityscapes'\n",
    "\n",
    "if train:\n",
    "    #Import dataset for training\n",
    "    train_set = datasets.Cityscapes(root=root_path, split='train', mode='fine', target_type='semantic', transform=transform, target_transform=target_transform)\n",
    "    quantity_train = len(train_set)\n",
    "    print('Quantity training data: '+ str(quantity_train))\n",
    "\n",
    "    #Prepare training dataset for NN\n",
    "    train_loader = data.DataLoader(train_set, batch_size=train_bs, shuffle=True)\n",
    "\n",
    "if validate or evaluate:\n",
    "    #Import dataset for validation\n",
    "    validation_set = datasets.Cityscapes(root=root_path, split='val', mode='fine', target_type='semantic', transform=transform, target_transform=target_transform)\n",
    "    quantity_validation = len(validation_set)\n",
    "    print('Quantity validation data: '+ str(quantity_validation))\n",
    "\n",
    "    #Prepare validation dataset for NN\n",
    "    validation_loader = data.DataLoader(validation_set, batch_size=validation_bs, shuffle=True)\n",
    "\n",
    "if evaluate:\n",
    "    #Import dataset for testing\n",
    "    test_set = datasets.Cityscapes(root=root_path, split='test', mode='fine', target_type='semantic', transform=transform, target_transform=target_transform)\n",
    "    quantity_test = len(test_set)\n",
    "    print('Quantity testing data: '+ str(quantity_test))\n",
    "\n",
    "    #Prepare test dataset for NN\n",
    "    test_loader = data.DataLoader(test_set, batch_size=test_bs, shuffle=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Printouts for testing train set\n",
    "\n",
    "#print(train_loader)\n",
    "#print(validation_loader)\n",
    "#print(test_loader)\n",
    "\n",
    "\n",
    "\n",
    "#Tensor to image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#img = cs.csViewer\n",
    "#img, segm = train_set[32]\n",
    "#print(img)\n",
    "#print(segm.size())\n",
    "#print(segm)\n",
    "#segm_norm = segm\n",
    "#segm_norm = segm\n",
    "#print(segm_norm.size())\n",
    "#targ_min = 32\n",
    "#targ_max = 0\n",
    "#for b in range(0, 1):\n",
    "#    for r in range(0,256):\n",
    "#        for c in range(0,512):\n",
    "#            #if label_mask[b][r][c] >= 32:\n",
    "#                #print(\"First eval: \" + str(label_mask[b][r][c]) + \", \" + str(b) + \", \" + str(r) + \", \" + str(c))\n",
    "#            if segm_norm[b][r][c] > targ_max:\n",
    "#                targ_max = segm_norm[b][r][c]\n",
    "#            if segm_norm[b][r][c] < targ_min:\n",
    "#                targ_min = segm_norm[b][r][c]\n",
    "#print(\"targ_min: \" + str(targ_min))\n",
    "#print(\"targ_max: \" + str(targ_max))\n",
    "\n",
    "#segm_norm = (segm*8)/256\n",
    "#print(segm_norm)\n",
    "#print(img.size())\n",
    "\n",
    "#imshow(torchvision.utils.make_grid(img))\n",
    "#imshow(torchvision.utils.make_grid(segm))\n",
    "\n",
    "#print(segm)\n",
    "#segm.show()\n",
    "#print(type(train_set))\n",
    "#print(train_set)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3) Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Define R2U-Net model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "# Here we have implemented the DEEPLABV3-RESNET101 architecture\n",
    "\n",
    "class DEEPLABV3_RESNET101(nn.Module):\n",
    "    def __init__(self, labels=34):\n",
    "        super(DEEPLABV3_RESNET101, self).__init__()\n",
    "\n",
    "        pass\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Load model to device\n",
    "model = DEEPLABV3_RESNET101().to(device)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4) Loss and Optimizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# optimizer variable\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5) Train model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Definition train and validation loop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def show_statistics(epoch, batch_id, loss_actual, input_image, label_mask, output_model):\n",
    "    print('[%d, %5d] train_loss: %.3f' % (epoch+1, batch_id+1, loss_actual.item()))\n",
    "\n",
    "    # print images\n",
    "    image2 = input_image.cpu()\n",
    "    imshow(torchvision.utils.make_grid(image2[0]))\n",
    "\n",
    "    label2 = label_mask.cpu()\n",
    "\n",
    "    plt.imshow(label2.detach().numpy()[0])\n",
    "    plt.show()\n",
    "\n",
    "    output2 = output_model.cpu()\n",
    "    output3 = output2.argmax(dim=1)\n",
    "\n",
    "    plt.imshow(output3.detach().numpy()[0])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def train_model(epoch, train_loader):\n",
    "    trainloader_loop = tqdm(train_loader)\n",
    "    printrate = int(quantity_train/(train_bs*10))\n",
    "    train_loss = 0.0\n",
    "\n",
    "    #Set model mode to train\n",
    "    model.train()\n",
    "\n",
    "    #Iterate over all batches in train_loader\n",
    "    for i, batch in enumerate(trainloader_loop):\n",
    "        #Input Image for forward pass\n",
    "        input_image = batch[0].to(device)\n",
    "\n",
    "        #Label \"image\" for comparing with loss function\n",
    "        label_mask = batch[1].to(device)\n",
    "        label_mask = label_mask.squeeze(1)\n",
    "\n",
    "        #Forward propagation\n",
    "        with torch.cuda.amp.autocast():\n",
    "            output_model = model(input_image)\n",
    "\n",
    "            loss = criterion(output_model, label_mask)\n",
    "\n",
    "            #Print with loss\n",
    "            train_loss += loss.item()\n",
    "            if i % printrate == 0:\n",
    "                show_statistics(epoch, i, loss, input_image, label_mask, output_model)\n",
    "\n",
    "        #Backward propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #update tqdm\n",
    "        trainloader_loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    print(\"Finished training!\")\n",
    "\n",
    "    #Calculate validation_loss\n",
    "    train_loss = train_loss/quantity_train\n",
    "\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "def validate_model(epoch, validation_loader):\n",
    "    validationloader_loop = tqdm(validation_loader)\n",
    "    printrate = int(quantity_validation/(validation_bs*10))\n",
    "    validation_loss = 0.0\n",
    "\n",
    "    #Set model mode to evaluation\n",
    "    model.eval()\n",
    "\n",
    "    #Iterate over all batches in validation_loader\n",
    "    for i, batch in enumerate(validationloader_loop):\n",
    "        #Input Image for forward pass\n",
    "        input_image = batch[0].to(device)\n",
    "\n",
    "        #Label \"image\" for comparing with loss function\n",
    "        label_mask = batch[1].to(device)\n",
    "        label_mask = label_mask.squeeze(1)\n",
    "\n",
    "        #Forward propagation\n",
    "        with torch.no_grad():\n",
    "            output_model = model(input_image)\n",
    "\n",
    "            loss = criterion(output_model, label_mask)\n",
    "\n",
    "            #Print with loss\n",
    "            validation_loss += loss.item()\n",
    "            if i % printrate == 0:\n",
    "                show_statistics(epoch, i, loss, input_image, label_mask, output_model)\n",
    "\n",
    "        #update tqdm\n",
    "        validationloader_loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    print(\"Finished validation!\")\n",
    "\n",
    "    #Calculate validation_loss\n",
    "    validation_loss = validation_loss/quantity_validation\n",
    "\n",
    "    return validation_loss\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Training and validation of the model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "\n",
    "#Load parameters\n",
    "file_name = 'savedata/task3/task_3_model_parameters-14_03_2021-01.pt'\n",
    "if os.path.isfile(file_name):\n",
    "    model = torch.load(file_name)\n",
    "\n",
    "#Statistical parameters\n",
    "train_loss = 0.0\n",
    "train_loss_history = []\n",
    "validation_loss = 0.0\n",
    "validation_loss_history = []\n",
    "learning_rate_history = []\n",
    "\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min', factor=0.05, patience=5, verbose=True)\n",
    "\n",
    "# Iterate over every epoch\n",
    "for epoch in range(epochs):\n",
    "    # Train model\n",
    "    if train:\n",
    "        train_loss = train_model(epoch, train_loader)\n",
    "        train_loss_history.append(train_loss)\n",
    "\n",
    "    # Validate model\n",
    "    if validate:\n",
    "        validation_loss = validate_model(epoch, validation_loader)\n",
    "        validation_loss_history.append(validation_loss)\n",
    "\n",
    "    # Learning rate history\n",
    "    learning_rate_history.append(learning_rate)\n",
    "\n",
    "    # Update Scheduler\n",
    "    scheduler.step(validation_loss)\n",
    "\n",
    "    torch.save(model, file_name)\n",
    "\n",
    "print(\"Finished train model!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Print lists of mean losses and scheduled learning for every epoch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Train loss of every epoch: \" + str(train_loss_history))\n",
    "print(\"Validation loss of every epoch: \" + str(validation_loss_history))\n",
    "print(\"Learning rate of every epoch: \" + str(learning_rate_history))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6) Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Evaluation metrics"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "\n",
    "def one_row(ground_truth, prediction):\n",
    "    pred = prediction.argmax(dim=1).view(1,-1)\n",
    "    pred = np.squeeze(pred.numpy())\n",
    "\n",
    "    truth = ground_truth.view(1,-1)\n",
    "    truth = np.squeeze(truth.numpy())\n",
    "\n",
    "    return truth.astype(float), pred.astype(float)\n",
    "\n",
    "\n",
    "def performance(multi_confusion_matrix, class_labels):\n",
    "    true_positive = []\n",
    "    false_positive = []\n",
    "    true_negative = []\n",
    "    false_negative = []\n",
    "\n",
    "    for i in class_labels:\n",
    "        true_positive.append(multi_confusion_matrix[i][[0],[0]][0])\n",
    "        false_positive.append(multi_confusion_matrix[i][[0],[1]][0])\n",
    "        true_negative.append(multi_confusion_matrix[i][[1],[1]][0])\n",
    "        false_negative.append(multi_confusion_matrix[i][[1],[0]][0])\n",
    "\n",
    "    positive = [true_positive, false_positive]\n",
    "    negative = [true_negative, false_negative]\n",
    "\n",
    "    return positive, negative\n",
    "\n",
    "\n",
    "def evaluate(ground_truth, predictions):\n",
    "    ground_truth2 = ground_truth.copy()\n",
    "    predictions2 = predictions.copy()\n",
    "\n",
    "    accuracy = 0.0\n",
    "    f1_score = np.zeros(34, dtype='float')\n",
    "    auc_score = 0.0\n",
    "    dice_coefficient = 0.0\n",
    "\n",
    "    listlen = min(len(ground_truth2),len(predictions2))\n",
    "\n",
    "    for l in range(0, listlen):\n",
    "        x = ground_truth2[l].cpu()\n",
    "        y = predictions2[l].cpu()\n",
    "\n",
    "\n",
    "        transform_tensors = one_row(x, y)\n",
    "\n",
    "        class_labels = list(range(0, 34))\n",
    "\n",
    "        multi_confusion_matrix = metrics.multilabel_confusion_matrix(transform_tensors[0], transform_tensors[1], labels=class_labels)\n",
    "\n",
    "        performance_model = performance(multi_confusion_matrix, class_labels)\n",
    "\n",
    "        positives = performance_model[0]\n",
    "        negatives = performance_model[1]\n",
    "\n",
    "        positives_total, negatives_total = 0,0\n",
    "        true_positives, false_positives, true_negatives, false_negatives = 0,0,0,0\n",
    "\n",
    "        for i in class_labels:\n",
    "            positives_total += positives[0][i] + positives[1][i]\n",
    "            negatives_total += negatives[0][i] + negatives[1][i]\n",
    "\n",
    "            true_positives += positives[0][i]\n",
    "            false_positives += positives[1][i]\n",
    "            true_negatives += negatives[0][i]\n",
    "            false_negatives += negatives[1][i]\n",
    "\n",
    "        # Accuracy\n",
    "        if (positives_total + negatives_total) != 0:\n",
    "            accuracy += (true_positives + true_negatives) / (positives_total + negatives_total)\n",
    "\n",
    "\n",
    "        # F1 score\n",
    "        f1 = []\n",
    "        for i in class_labels:\n",
    "            denominator = 2 * positives[0][i] + positives[1][i] + negatives[1][i]\n",
    "            if denominator != 0:\n",
    "                f1.append(2 * positives[0][1] / denominator)\n",
    "            else:\n",
    "                f1.append(0.0)\n",
    "\n",
    "        f1_score += f1\n",
    "\n",
    "\n",
    "        # AUC-ROC score\n",
    "        #auc_score += metrics.roc_auc_score(transform_tensors[0], transform_tensors[1], multi_class='ovr', labels=class_labels)\n",
    "\n",
    "\n",
    "        # DICE coefficient\n",
    "        if (2 * true_positives + false_positives + false_negatives) != 0:\n",
    "            dice_coefficient += (2 * true_positives) / (2 * true_positives + false_positives + false_negatives)\n",
    "\n",
    "\n",
    "    accuracy = accuracy / listlen\n",
    "    f1_score = f1_score / listlen\n",
    "    auc_score = auc_score / listlen\n",
    "    dice_coefficient = dice_coefficient / listlen\n",
    "\n",
    "    return accuracy, f1_score, auc_score, dice_coefficient"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "f1_score = -1000.0\n",
    "auc_score = -1000.0\n",
    "dice_coefficient = -1000.0\n",
    "\n",
    "truth_list = []\n",
    "pred_list = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Only during the programming. We dont want want to build the testlist every time\n",
    "breaker = False\n",
    "\n",
    "if evaluate:\n",
    "    testloader_loop = tqdm(validation_loader)\n",
    "\n",
    "    #Set model mode to evaluation\n",
    "    model.eval()\n",
    "\n",
    "    #Iterate over all batches in validation_loader\n",
    "    for i, batch in enumerate(testloader_loop):\n",
    "        if breaker:\n",
    "            break\n",
    "        #Input Image for forward pass\n",
    "        test_image = batch[0].to(device)\n",
    "\n",
    "        #Label \"image\" for comparing with loss function\n",
    "        ground_truth = batch[1].cpu()\n",
    "        ground_truth = ground_truth.squeeze(1)\n",
    "\n",
    "        #Forward propagation\n",
    "        with torch.no_grad():\n",
    "            prediction = model(test_image)\n",
    "\n",
    "        truth_list.append(ground_truth.float())\n",
    "        pred_list.append(prediction.cpu().float())\n",
    "\n",
    "    scores = evaluate(truth_list, pred_list)\n",
    "\n",
    "    accuracy = scores[0]\n",
    "    f1_score = scores[1]\n",
    "    auc_score = scores[2]\n",
    "    dice_coefficient = scores[3]\n",
    "\n",
    "    print(\"Finished evaluation!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Print lists of scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Accuracy: \" + str(round((accuracy*100), 2)) + \"%\")\n",
    "print(\"F1 score: \" + str(f1_score*100) + \"%\")\n",
    "print(\"AUC score: \" + str(round((auc_score*100), 2)) + \"%\")\n",
    "print(\"DICE coefficient: \" + str(round((dice_coefficient*100), 2)) + \"%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Evaluation plots"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.9 Visualize results(0.5 points)\n",
    "For any 10 images in the dataset, show the images along the with their segmentation mask."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "\n",
    "for i, batch in enumerate(test_loader):\n",
    "    if i % 10 == 0:\n",
    "        input_image = batch[0].to(device)\n",
    "        label_mask = batch[1].squeeze(1)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output_model = model(input_image.to(device))\n",
    "\n",
    "        # print images\n",
    "        image2 = input_image.cpu()\n",
    "        imshow(torchvision.utils.make_grid(image2[0]))\n",
    "\n",
    "        label2 = label_mask.cpu()\n",
    "\n",
    "        plt.imshow(label2.detach().numpy()[0])\n",
    "        plt.show()\n",
    "\n",
    "        output2 = output_model.cpu()\n",
    "        output3 = output2.argmax(dim=1)\n",
    "\n",
    "        plt.imshow(output3.detach().numpy()[0])\n",
    "        plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}